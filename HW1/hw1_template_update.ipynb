{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_Te27fi-0pP"
      },
      "source": [
        "# **HW1: Regression**\n",
        "In *assignment 1*, you need to finish:\n",
        "\n",
        "1.  Basic Part: Implement two regression models to predict the Systolic blood pressure (SBP) of a patient. You will need to implement **both Matrix Inversion and Gradient Descent**.\n",
        "\n",
        "\n",
        "> *   Step 1: Split Data\n",
        "> *   Step 2: Preprocess Data\n",
        "> *   Step 3: Implement Regression\n",
        "> *   Step 4: Make Prediction\n",
        "> *   Step 5: Train Model and Generate Result\n",
        "\n",
        "2.  Advanced Part: Implement one regression model to predict the SBP of multiple patients in a different way than the basic part. You can choose **either** of the two methods for this part."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wDdnos-4uUv"
      },
      "source": [
        "# **1. Basic Part (55%)**\n",
        "In the first part, you need to implement the regression to predict SBP from the given DBP\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_EVqWlB-DTF"
      },
      "source": [
        "## 1.1 Matrix Inversion Method (25%)\n",
        "\n",
        "\n",
        "*   Save the prediction result in a csv file **hw1_basic_mi.csv**\n",
        "*   Print your coefficient\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzCR7vk9BFkf"
      },
      "source": [
        "### *Import Packages*\n",
        "\n",
        "> Note: You **cannot** import any other package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2102,
      "metadata": {
        "id": "HL5XjqFf4wSj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import csv\n",
        "import math\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnWjrzi0dMPz"
      },
      "source": [
        "### *Global attributes*\n",
        "Define the global attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2103,
      "metadata": {
        "id": "EWLDPOlHBbcK"
      },
      "outputs": [],
      "source": [
        "training_dataroot = 'hw1_basic_training.csv' # Training data file file named as 'hw1_basic_training.csv'\n",
        "testing_dataroot = 'hw1_basic_testing.csv'   # Testing data file named as 'hw1_basic_training.csv'\n",
        "output_dataroot = 'hw1_basic_mi.csv' # Output file will be named as 'hw1_basic.csv'\n",
        "\n",
        "training_datalist =  [] # Training datalist, saved as numpy array\n",
        "testing_datalist =  [] # Testing datalist, saved as numpy array\n",
        "\n",
        "output_datalist =  [] # Your prediction, should be 20 * 1 matrix and saved as numpy array\n",
        "                      # The format of each row should be ['sbp']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsFC-cvqIcYK"
      },
      "source": [
        "You can add your own global attributes here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2104,
      "metadata": {
        "id": "OUbS2BEgcut6"
      },
      "outputs": [],
      "source": [
        "def MAPE(y_ans, y_prediction):\n",
        "    return np.mean(np.abs((y_ans - y_prediction) / y_ans)) * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUoRFoQjBW5S"
      },
      "source": [
        "### *Load the Input File*\n",
        "First, load the basic input file **hw1_basic_training.csv** and **hw1_basic_testing.csv**\n",
        "\n",
        "Input data would be stored in *training_datalist* and *testing_datalist*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2105,
      "metadata": {
        "id": "dekR1KnqBtI6"
      },
      "outputs": [],
      "source": [
        "# Read input csv to datalist\n",
        "with open(training_dataroot, newline='') as csvfile:\n",
        "    training_datalist = np.array(list(csv.reader(csvfile)))\n",
        "    training_datalist = np.delete(training_datalist, 0, 0)\n",
        "\n",
        "with open(testing_dataroot, newline='') as csvfile:\n",
        "    testing_datalist = np.array(list(csv.reader(csvfile)))\n",
        "    testing_datalist = np.delete(testing_datalist, 0, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kYPuikLCFx4"
      },
      "source": [
        "### *Implement the Regression Model*\n",
        "\n",
        "> Note: It is recommended to use the functions we defined, you can also define your own functions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWwdx06JNEYs"
      },
      "source": [
        "#### Step 1: Split Data\n",
        "Split data in *training_datalist* into training dataset and validation dataset\n",
        "* Validation dataset is used to validate your own model without the testing data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2106,
      "metadata": {
        "id": "USDciENcB-5F"
      },
      "outputs": [],
      "source": [
        "def split_data(training_datalist: np.array) -> (np.array, np.array):\n",
        "    train_nums = int(len(training_datalist) * 0.8)\n",
        "    return training_datalist[ : train_nums], training_datalist[train_nums : ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-3Qln4aNgVy"
      },
      "source": [
        "#### Step 2: Preprocess Data\n",
        "Handle the unreasonable data\n",
        "> Hint: Outlier and missing data can be handled by removing the data or adding the values with the help of statistics  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2107,
      "metadata": {
        "id": "XXvW1n_5NkQ5"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(training_datalist: np.array, boundary: int) -> np.array:\n",
        "    train_nums = len(training_datalist)\n",
        "\n",
        "    dbp = np.array([[data[0]] for data in training_datalist]).astype(float)\n",
        "    sbp = np.array([[data[1]] for data in training_datalist]).astype(float)\n",
        "\n",
        "    dbp_mean = np.mean(dbp)\n",
        "    dbp_std = np.std(dbp)\n",
        "    sbp_mean = np.mean(sbp)\n",
        "    sbp_std = np.std(sbp)\n",
        "\n",
        "    i = -1\n",
        "    while i < train_nums - 1:\n",
        "        i += 1\n",
        "\n",
        "        dbp_below_threshold = dbp[i] < dbp_mean - boundary * dbp_std\n",
        "        dbp_above_threshold = dbp[i] > dbp_mean + boundary * dbp_std\n",
        "        sbp_below_threshold = sbp[i] < sbp_mean - boundary * sbp_std\n",
        "        sbp_above_threshold = sbp[i] > sbp_mean + boundary * sbp_std\n",
        "\n",
        "        if (dbp_below_threshold or dbp_above_threshold) or (sbp_below_threshold or sbp_above_threshold):\n",
        "            training_datalist = np.delete(training_datalist, i, 0)\n",
        "            train_nums -= 1\n",
        "            i -= 1\n",
        "\n",
        "    return training_datalist.astype(float)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDLpJmQUN3V6"
      },
      "source": [
        "#### Step 3: Implement Regression\n",
        "> use Matrix Inversion to finish this part\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2108,
      "metadata": {
        "id": "Tx9n1_23N8C0"
      },
      "outputs": [],
      "source": [
        "def matrix_inversion(train_set: np.array) -> np.array:\n",
        "    x = np.array([[1, data[0]] for data in train_set]).astype(float)\n",
        "    y_ans = np.array([[data[1]] for data in train_set]).astype(float)\n",
        "    return np.linalg.inv(x.T.dot(x)).dot(x.T).dot(y_ans)\n",
        "\n",
        "def validation(validate_set: np.array, coefficient: np.array) -> str:\n",
        "    validate_x = np.array([[1, data[0]] for data in validate_set])\n",
        "    validate_y = np.array([[data[1]] for data in validate_set])\n",
        "    validate_y_prediction = validate_x.dot(coefficient).astype(int)\n",
        "    return f'MAPE of validation set : {MAPE(validate_y, validate_y_prediction)}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NxRNFwyN8xd"
      },
      "source": [
        "#### Step 4: Make Prediction\n",
        "Make prediction of testing dataset and store the value in *output_datalist*\n",
        "The final *output_datalist* should look something like this \n",
        "> [ [100], [80], ... , [90] ] where each row contains the predicted SBP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2109,
      "metadata": {
        "id": "EKlDIC2-N_lk"
      },
      "outputs": [],
      "source": [
        "def make_prediction(testing_datalist: np.array, coefficient: np.array) -> np.array:\n",
        "    testing_x = np.array([[1, data[0]] for data in testing_datalist]).astype(float)\n",
        "    return testing_x.dot(coefficient).astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCd0Z6izOCwq"
      },
      "source": [
        "#### Step 5: Train Model and Generate Result\n",
        "\n",
        "> Notice: **Remember to output the coefficients of the model here**, otherwise 5 points would be deducted\n",
        "* If your regression model is *3x^2 + 2x^1 + 1*, your output would be:\n",
        "```\n",
        "3 2 1\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2110,
      "metadata": {
        "id": "iCL92EPKOFIn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAPE of validation set : 5.000690216635821\n",
            "\n",
            "---------- Coefficient ----------\n",
            "0.9210072989326239 52.277057839995386 "
          ]
        }
      ],
      "source": [
        "train, validate = split_data(preprocess_data(training_datalist, 2))\n",
        "coefficient = matrix_inversion(train)\n",
        "output_datalist = make_prediction(testing_datalist, coefficient)\n",
        "\n",
        "print(validation(validate, coefficient))\n",
        "print('\\n' + '-' * 10 + ' Coefficient ' + '-' * 10)\n",
        "\n",
        "for coe in coefficient[::-1]:\n",
        "    print(coe[0], end = ' ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8Jhd8wAOk3D"
      },
      "source": [
        "### *Write the Output File*\n",
        "Write the prediction to output csv\n",
        "> Format: 'sbp'\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2111,
      "metadata": {
        "id": "tYQVYLlKOtDB"
      },
      "outputs": [],
      "source": [
        "with open(output_dataroot, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
        "\twriter = csv.writer(csvfile)\n",
        "\tfor row in output_datalist:\n",
        "\t\twriter.writerow(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1J3WOhglA9ML"
      },
      "source": [
        "## 1.2 Gradient Descent Method (30%)\n",
        "\n",
        "\n",
        "*   Save the prediction result in a csv file **hw1_basic_gd.csv**\n",
        "*   Output your coefficient update in a csv file **hw1_basic_coefficient.csv**\n",
        "*   Print your coefficient\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkMqa_xjXhEv"
      },
      "source": [
        "### *Global attributes*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2112,
      "metadata": {
        "id": "wNZtRWUeXpEu"
      },
      "outputs": [],
      "source": [
        "output_dataroot = 'hw1_basic_gd.csv' # Output file will be named as 'hw1_basic.csv'\n",
        "coefficient_output_dataroot = 'hw1_basic_coefficient.csv'\n",
        "\n",
        "training_datalist =  [] # Training datalist, saved as numpy array\n",
        "testing_datalist =  [] # Testing datalist, saved as numpy array\n",
        "\n",
        "output_datalist =  [] # Your prediction, should be 20 * 1 matrix and saved as numpy array\n",
        "                      # The format of each row should be ['sbp']\n",
        "\n",
        "coefficient_output = [] # Your coefficient update during gradient descent\n",
        "                   # Should be a (number of iterations * number_of coefficient) matrix\n",
        "                   # The format of each row should be ['w0', 'w1', ...., 'wn']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5DeHxdLdai3"
      },
      "source": [
        "Your own global attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2113,
      "metadata": {
        "id": "_2IO5tYSdaFd"
      },
      "outputs": [],
      "source": [
        "# Read input csv to datalist\n",
        "with open(training_dataroot, newline='') as csvfile:\n",
        "    training_datalist = np.array(list(csv.reader(csvfile)))\n",
        "    training_datalist = np.delete(training_datalist, 0, 0)\n",
        "\n",
        "with open(testing_dataroot, newline='') as csvfile:\n",
        "    testing_datalist = np.array(list(csv.reader(csvfile)))\n",
        "    testing_datalist = np.delete(testing_datalist, 0, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVBLT1aqXuW0"
      },
      "source": [
        "### *Implement the Regression Model*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecPWpcOnXhCZ"
      },
      "source": [
        "#### Step 1: Split Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2114,
      "metadata": {
        "id": "1PEf_qGvYHu0"
      },
      "outputs": [],
      "source": [
        "def split_data(training_datalist: np.array) -> (np.array, np.array):\n",
        "    train_nums = int(len(training_datalist) * 0.8)\n",
        "    return training_datalist[ : train_nums], training_datalist[train_nums : ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpSoPDPKX56w"
      },
      "source": [
        "#### Step 2: Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2115,
      "metadata": {
        "id": "uLTXOWRwYHiS"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(training_datalist: np.array, width: float) -> np.array:\n",
        "    train_nums = len(training_datalist)\n",
        "\n",
        "    dbp = np.array([[data[0]] for data in training_datalist]).astype(float)\n",
        "    sbp = np.array([[data[1]] for data in training_datalist]).astype(float)\n",
        "\n",
        "    dbp_mean = np.mean(dbp)\n",
        "    dbp_std = np.std(dbp)\n",
        "    sbp_mean = np.mean(sbp)\n",
        "    sbp_std = np.std(sbp)\n",
        "\n",
        "    i = -1\n",
        "    while i < train_nums - 1:\n",
        "        i += 1\n",
        "\n",
        "        dbp_below_threshold = dbp[i] < dbp_mean - width * dbp_std\n",
        "        dbp_above_threshold = dbp[i] > dbp_mean + width * dbp_std\n",
        "        sbp_below_threshold = sbp[i] < sbp_mean - width * sbp_std\n",
        "        sbp_above_threshold = sbp[i] > sbp_mean + width * sbp_std\n",
        "\n",
        "        if (dbp_below_threshold or dbp_above_threshold) or (sbp_below_threshold or sbp_above_threshold):\n",
        "            training_datalist = np.delete(training_datalist, i, 0)\n",
        "            train_nums -= 1\n",
        "            i -= 1\n",
        "\n",
        "    return training_datalist.astype(float)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TV_y82gXX6a-"
      },
      "source": [
        "#### Step 3: Implement Regression\n",
        "> use Gradient Descent to finish this part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2116,
      "metadata": {
        "id": "-635Ee00YHTE"
      },
      "outputs": [],
      "source": [
        "def gradient_descent(epoch: int, learning_rate: float, train_set: np.array) -> np.array:\n",
        "    def gradient_of_loss(y_ans: np.array, y_predict: np.array, x: np.array) -> np.array: \n",
        "        return (-2 * (y_ans - y_predict)).T.dot(x).T\n",
        "    \n",
        "    coefficient = np.array([[50], [0.9]]).astype(float)\n",
        "    x = np.array([[1, data[0]] for data in train_set]).astype(float)\n",
        "    y_ans = np.array([[data[1]] for data in train_set]).astype(float)\n",
        "    y_predict = x.dot(coefficient).astype(float)\n",
        "\n",
        "    for e in range(epoch):\n",
        "        coefficient -= learning_rate * gradient_of_loss(y_ans, y_predict, x)\n",
        "        y_predict = x.dot(coefficient)\n",
        "        coefficient_output.append(coefficient)\n",
        "        print(f'Epoch {e + 1:2} : MAPE = {MAPE(y_ans, y_predict)}')\n",
        "    \n",
        "    return coefficient\n",
        "    \n",
        "def validation(validate_set: np.array, coefficient: np.array) -> str:\n",
        "    validate_x = np.array([[1, data[0]] for data in validate_set])\n",
        "    validate_y = np.array([[data[1]] for data in validate_set])\n",
        "    validate_y_prediction = validate_x.dot(coefficient).astype(int)\n",
        "    return f'MAPE of validation set : {MAPE(validate_y, validate_y_prediction)}'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLuPxs2ZX21S"
      },
      "source": [
        "#### Step 4: Make Prediction\n",
        "\n",
        "Make prediction of testing dataset and store the values in *output_datalist*\n",
        "The final *output_datalist* should look something like this \n",
        "> [ [100], [80], ... , [90] ] where each row contains the predicted SBP\n",
        "\n",
        "Remember to also store your coefficient update in *coefficient_output*\n",
        "The final *coefficient_output* should look something like this\n",
        "> [ [1, 0, 3, 5], ... , [0.1, 0.3, 0.2, 0.5] ] where each row contains the [w0, w1, ..., wn] of your coefficient\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2117,
      "metadata": {
        "id": "8pnNDlQeYGtE"
      },
      "outputs": [],
      "source": [
        "def make_prediction(testing_datalist: np.array, coefficient: np.array) -> np.array:\n",
        "    testing_x = np.array([[1, data[0]] for data in testing_datalist]).astype(float)\n",
        "    return testing_x.dot(coefficient).astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IScbxxMAYAgZ"
      },
      "source": [
        "#### Step 5: Train Model and Generate Result\n",
        "\n",
        "> Notice: **Remember to output the coefficients of the model here**, otherwise 5 points would be deducted\n",
        "* If your regression model is *3x^2 + 2x^1 + 1*, your output would be:\n",
        "```\n",
        "3 2 1\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2118,
      "metadata": {
        "id": "90EisOc7YG-N"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch  1 : MAPE = 4.8884711898988344\n",
            "Epoch  2 : MAPE = 4.92717997279329\n",
            "Epoch  3 : MAPE = 4.943203113903013\n",
            "Epoch  4 : MAPE = 4.9476709834159145\n",
            "Epoch  5 : MAPE = 4.948830525460115\n",
            "Epoch  6 : MAPE = 4.949120445821383\n",
            "Epoch  7 : MAPE = 4.94919295082846\n",
            "Epoch  8 : MAPE = 4.949211099513473\n",
            "Epoch  9 : MAPE = 4.949215658497023\n",
            "Epoch 10 : MAPE = 4.949216819899923\n",
            "Epoch 11 : MAPE = 4.949217131868798\n",
            "Epoch 12 : MAPE = 4.9492172314694125\n",
            "Epoch 13 : MAPE = 4.9492172779754835\n",
            "Epoch 14 : MAPE = 4.949217311207263\n",
            "Epoch 15 : MAPE = 4.949217341120262\n",
            "Epoch 16 : MAPE = 4.949217370203477\n",
            "Epoch 17 : MAPE = 4.949217399079183\n",
            "Epoch 18 : MAPE = 4.949217427902959\n",
            "Epoch 19 : MAPE = 4.949217456713698\n",
            "Epoch 20 : MAPE = 4.949217485521125\n",
            "Epoch 21 : MAPE = 4.949217514327674\n",
            "Epoch 22 : MAPE = 4.949217543133948\n",
            "Epoch 23 : MAPE = 4.9492175719401015\n",
            "Epoch 24 : MAPE = 4.949217600746173\n",
            "Epoch 25 : MAPE = 4.949217629552173\n",
            "Epoch 26 : MAPE = 4.949217658358101\n",
            "Epoch 27 : MAPE = 4.949217687163961\n",
            "Epoch 28 : MAPE = 4.949217715969748\n",
            "Epoch 29 : MAPE = 4.949217744775466\n",
            "Epoch 30 : MAPE = 4.9492177735811165\n",
            "Epoch 31 : MAPE = 4.949217802386697\n",
            "Epoch 32 : MAPE = 4.949217831192207\n",
            "Epoch 33 : MAPE = 4.9492178599976455\n",
            "Epoch 34 : MAPE = 4.949217888803017\n",
            "Epoch 35 : MAPE = 4.949217917608316\n",
            "Epoch 36 : MAPE = 4.949217946413546\n",
            "Epoch 37 : MAPE = 4.9492179752187075\n",
            "Epoch 38 : MAPE = 4.949218004023799\n",
            "Epoch 39 : MAPE = 4.949218032828819\n",
            "Epoch 40 : MAPE = 4.949218061633771\n",
            "Epoch 41 : MAPE = 4.949218090438652\n",
            "Epoch 42 : MAPE = 4.949218119243463\n",
            "Epoch 43 : MAPE = 4.949218148048207\n",
            "Epoch 44 : MAPE = 4.949218176852878\n",
            "Epoch 45 : MAPE = 4.949218205657482\n",
            "Epoch 46 : MAPE = 4.949218234462012\n",
            "Epoch 47 : MAPE = 4.949218263266475\n",
            "Epoch 48 : MAPE = 4.949218292070869\n",
            "Epoch 49 : MAPE = 4.949218320875193\n",
            "Epoch 50 : MAPE = 4.949218349679445\n",
            "Epoch 51 : MAPE = 4.9492183784836286\n",
            "Epoch 52 : MAPE = 4.949218407287743\n",
            "Epoch 53 : MAPE = 4.949218436091788\n",
            "Epoch 54 : MAPE = 4.949218464895762\n",
            "Epoch 55 : MAPE = 4.949218493699666\n",
            "Epoch 56 : MAPE = 4.949218522503502\n",
            "Epoch 57 : MAPE = 4.949218551307264\n",
            "Epoch 58 : MAPE = 4.949218580110961\n",
            "Epoch 59 : MAPE = 4.949218608914588\n",
            "Epoch 60 : MAPE = 4.949218637718145\n",
            "Epoch 61 : MAPE = 4.94921866652163\n",
            "Epoch 62 : MAPE = 4.949218695325044\n",
            "Epoch 63 : MAPE = 4.949218724128393\n",
            "Epoch 64 : MAPE = 4.949218752931668\n",
            "Epoch 65 : MAPE = 4.949218781734875\n",
            "Epoch 66 : MAPE = 4.949218810538011\n",
            "Epoch 67 : MAPE = 4.9492188393410785\n",
            "Epoch 68 : MAPE = 4.949218868144076\n",
            "Epoch 69 : MAPE = 4.949218896947006\n",
            "Epoch 70 : MAPE = 4.94921892574986\n",
            "Epoch 71 : MAPE = 4.9492189545526495\n",
            "Epoch 72 : MAPE = 4.949218983355367\n",
            "Epoch 73 : MAPE = 4.949219012158015\n",
            "Epoch 74 : MAPE = 4.949219040960596\n",
            "Epoch 75 : MAPE = 4.949219069763104\n",
            "Epoch 76 : MAPE = 4.949219098565543\n",
            "Epoch 77 : MAPE = 4.949219127367913\n",
            "Epoch 78 : MAPE = 4.949219156170212\n",
            "Epoch 79 : MAPE = 4.949219184972443\n",
            "Epoch 80 : MAPE = 4.9492192137746\n",
            "Epoch 81 : MAPE = 4.949219242576692\n",
            "Epoch 82 : MAPE = 4.949219271378713\n",
            "Epoch 83 : MAPE = 4.949219300180663\n",
            "Epoch 84 : MAPE = 4.949219328982545\n",
            "Epoch 85 : MAPE = 4.949219357784356\n",
            "Epoch 86 : MAPE = 4.949219386586097\n",
            "Epoch 87 : MAPE = 4.949219415387769\n",
            "Epoch 88 : MAPE = 4.949219444189372\n",
            "Epoch 89 : MAPE = 4.949219472990904\n",
            "Epoch 90 : MAPE = 4.949219501792364\n",
            "Epoch 91 : MAPE = 4.949219530593758\n",
            "Epoch 92 : MAPE = 4.949219559395079\n",
            "Epoch 93 : MAPE = 4.949219588196334\n",
            "Epoch 94 : MAPE = 4.949219616997515\n",
            "Epoch 95 : MAPE = 4.94921964579863\n",
            "Epoch 96 : MAPE = 4.949219674599672\n",
            "Epoch 97 : MAPE = 4.949219703400646\n",
            "Epoch 98 : MAPE = 4.949219732201552\n",
            "Epoch 99 : MAPE = 4.949219761002386\n",
            "Epoch 100 : MAPE = 4.94921978980315\n",
            "Epoch 101 : MAPE = 4.949219818603845\n",
            "Epoch 102 : MAPE = 4.94921984740447\n",
            "Epoch 103 : MAPE = 4.949219876205024\n",
            "Epoch 104 : MAPE = 4.949219905005511\n",
            "Epoch 105 : MAPE = 4.949219933805925\n",
            "Epoch 106 : MAPE = 4.949219962606271\n",
            "Epoch 107 : MAPE = 4.949219991406548\n",
            "Epoch 108 : MAPE = 4.949220020206755\n",
            "Epoch 109 : MAPE = 4.949220049006891\n",
            "Epoch 110 : MAPE = 4.949220077806958\n",
            "Epoch 111 : MAPE = 4.949220106606955\n",
            "Epoch 112 : MAPE = 4.949220135406881\n",
            "Epoch 113 : MAPE = 4.94922016420674\n",
            "Epoch 114 : MAPE = 4.949220193006527\n",
            "Epoch 115 : MAPE = 4.949220221806244\n",
            "Epoch 116 : MAPE = 4.949220250605895\n",
            "Epoch 117 : MAPE = 4.949220279405471\n",
            "Epoch 118 : MAPE = 4.949220308204978\n",
            "Epoch 119 : MAPE = 4.9492203370044185\n",
            "Epoch 120 : MAPE = 4.949220365803787\n",
            "Epoch 121 : MAPE = 4.949220394603087\n",
            "Epoch 122 : MAPE = 4.949220423402316\n",
            "Epoch 123 : MAPE = 4.949220452201477\n",
            "Epoch 124 : MAPE = 4.949220481000566\n",
            "Epoch 125 : MAPE = 4.949220509799587\n",
            "Epoch 126 : MAPE = 4.949220538598538\n",
            "Epoch 127 : MAPE = 4.949220567397416\n",
            "Epoch 128 : MAPE = 4.949220596196229\n",
            "Epoch 129 : MAPE = 4.949220624994971\n",
            "Epoch 130 : MAPE = 4.949220653793642\n",
            "Epoch 131 : MAPE = 4.949220682592244\n",
            "Epoch 132 : MAPE = 4.949220711390774\n",
            "Epoch 133 : MAPE = 4.9492207401892365\n",
            "Epoch 134 : MAPE = 4.9492207689876295\n",
            "Epoch 135 : MAPE = 4.9492207977859515\n",
            "Epoch 136 : MAPE = 4.949220826584204\n",
            "Epoch 137 : MAPE = 4.9492208553823875\n",
            "Epoch 138 : MAPE = 4.9492208841805\n",
            "Epoch 139 : MAPE = 4.949220912978544\n",
            "Epoch 140 : MAPE = 4.949220941776518\n",
            "Epoch 141 : MAPE = 4.949220970574421\n",
            "Epoch 142 : MAPE = 4.949220999372255\n",
            "Epoch 143 : MAPE = 4.949221028170021\n",
            "Epoch 144 : MAPE = 4.949221056967714\n",
            "Epoch 145 : MAPE = 4.9492210857653385\n",
            "Epoch 146 : MAPE = 4.949221114562895\n",
            "Epoch 147 : MAPE = 4.949221143360381\n",
            "Epoch 148 : MAPE = 4.949221172157795\n",
            "Epoch 149 : MAPE = 4.949221200955142\n",
            "Epoch 150 : MAPE = 4.949221229752416\n",
            "Epoch 151 : MAPE = 4.949221258549622\n",
            "Epoch 152 : MAPE = 4.949221287346759\n",
            "Epoch 153 : MAPE = 4.949221316143825\n",
            "Epoch 154 : MAPE = 4.949221344940823\n",
            "Epoch 155 : MAPE = 4.9492213737377515\n",
            "Epoch 156 : MAPE = 4.949221402534608\n",
            "Epoch 157 : MAPE = 4.949221431331397\n",
            "Epoch 158 : MAPE = 4.949221460128113\n",
            "Epoch 159 : MAPE = 4.949221488924761\n",
            "Epoch 160 : MAPE = 4.949221517721339\n",
            "Epoch 161 : MAPE = 4.9492215465178475\n",
            "Epoch 162 : MAPE = 4.949221575314288\n",
            "Epoch 163 : MAPE = 4.949221604110659\n",
            "Epoch 164 : MAPE = 4.949221632906955\n",
            "Epoch 165 : MAPE = 4.949221661703184\n",
            "Epoch 166 : MAPE = 4.949221690499344\n",
            "Epoch 167 : MAPE = 4.949221719295434\n",
            "Epoch 168 : MAPE = 4.949221748091456\n",
            "Epoch 169 : MAPE = 4.949221776887405\n",
            "Epoch 170 : MAPE = 4.949221805683286\n",
            "Epoch 171 : MAPE = 4.949221834479096\n",
            "Epoch 172 : MAPE = 4.94922186327484\n",
            "Epoch 173 : MAPE = 4.949221892070509\n",
            "Epoch 174 : MAPE = 4.949221920866111\n",
            "Epoch 175 : MAPE = 4.949221949661643\n",
            "Epoch 176 : MAPE = 4.949221978457105\n",
            "Epoch 177 : MAPE = 4.949222007252498\n",
            "Epoch 178 : MAPE = 4.94922203604782\n",
            "Epoch 179 : MAPE = 4.949222064843073\n",
            "Epoch 180 : MAPE = 4.949222093638255\n",
            "Epoch 181 : MAPE = 4.94922212243337\n",
            "Epoch 182 : MAPE = 4.949222151228412\n",
            "Epoch 183 : MAPE = 4.949222180023387\n",
            "Epoch 184 : MAPE = 4.94922220881829\n",
            "Epoch 185 : MAPE = 4.949222237613125\n",
            "Epoch 186 : MAPE = 4.949222266407889\n",
            "Epoch 187 : MAPE = 4.949222295202584\n",
            "Epoch 188 : MAPE = 4.949222323997208\n",
            "Epoch 189 : MAPE = 4.9492223527917645\n",
            "Epoch 190 : MAPE = 4.949222381586249\n",
            "Epoch 191 : MAPE = 4.949222410380667\n",
            "Epoch 192 : MAPE = 4.9492224391750135\n",
            "Epoch 193 : MAPE = 4.949222467969289\n",
            "Epoch 194 : MAPE = 4.949222496763495\n",
            "Epoch 195 : MAPE = 4.94922252555763\n",
            "Epoch 196 : MAPE = 4.949222554351697\n",
            "Epoch 197 : MAPE = 4.949222583145694\n",
            "Epoch 198 : MAPE = 4.949222611939621\n",
            "Epoch 199 : MAPE = 4.94922264073348\n",
            "Epoch 200 : MAPE = 4.949222669527267\n",
            "\n",
            "---------- MAPE ----------\n",
            "MAPE of validation set : 4.9843450987673075\n",
            "\n",
            "---------- Coefficient ----------\n",
            "0.9486378390461381 50.00169355057738 "
          ]
        }
      ],
      "source": [
        "train, validate = split_data(preprocess_data(training_datalist, 2))\n",
        "coefficient = gradient_descent(200, 0.0000005, train)\n",
        "output_datalist = make_prediction(testing_datalist, coefficient)\n",
        "\n",
        "print('\\n' + '-' * 10 + ' MAPE ' + '-' * 10)\n",
        "print(validation(validate, coefficient))\n",
        "print('\\n' + '-' * 10 + ' Coefficient ' + '-' * 10)\n",
        "\n",
        "for coe in coefficient[::-1]:\n",
        "    print(coe[0], end = ' ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1DpV_HcYFpl"
      },
      "source": [
        "### *Write the Output File*\n",
        "\n",
        "Write the prediction to output csv\n",
        "> Format: 'sbp'\n",
        "\n",
        "**Write the coefficient update to csv**\n",
        "> Format: 'w0', 'w1', ..., 'wn'\n",
        ">*   The number of columns is based on your number of coefficient\n",
        ">*   The number of row is based on your number of iterations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2119,
      "metadata": {
        "id": "NLSHgpDvDXNI"
      },
      "outputs": [],
      "source": [
        "with open(output_dataroot, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
        "\twriter = csv.writer(csvfile)\n",
        "\tfor row in output_datalist:\n",
        "\t\twriter.writerow(row)\n",
        "\n",
        "with open(coefficient_output_dataroot, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
        "\twriter = csv.writer(csvfile)\n",
        "\tfor row in coefficient_output:\n",
        "\t\twriter.writerow(row.flatten())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rx4408qg4xMQ"
      },
      "source": [
        "# **2. Advanced Part (40%)**\n",
        "In the second part, you need to implement the regression in a different way than the basic part to help your predictions of multiple patients SBP.\n",
        "\n",
        "You can choose **either** Matrix Inversion or Gradient Descent method.\n",
        "\n",
        "The training data will be in **hw1_advanced_training.csv** and the testing data will be in **hw1_advanced_testing.csv**.\n",
        "\n",
        "Output your prediction in **hw1_advanced.csv**\n",
        "\n",
        "Notice:\n",
        "> You cannot import any other package other than those given\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Input the training and testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2120,
      "metadata": {
        "id": "v66HUClZcxaE"
      },
      "outputs": [],
      "source": [
        "training_dataroot = 'hw1_advanced_training.csv' # Training data file file named as 'hw1_basic_training.csv'\n",
        "testing_dataroot = 'hw1_advanced_testing.csv'   # Testing data file named as 'hw1_basic_training.csv'\n",
        "output_dataroot = 'hw1_advanced.csv' # Output file will be named as 'hw1_basic.csv'\n",
        "\n",
        "training_datalist =  [] # Training datalist, saved as numpy array\n",
        "testing_datalist =  [] # Testing datalist, saved as numpy array\n",
        "\n",
        "output_datalist =  [] # Your prediction, should be 220 * 1 matrix and saved as numpy array\n",
        "                      # The format of each row should be ['sbp']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1. read the training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2121,
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_data() -> (list, list, np.array):\n",
        "    train_id = []\n",
        "    train_time = []\n",
        "    train_data = []\n",
        "\n",
        "    training_data = []\n",
        "    with open(training_dataroot, newline='') as csvfile:\n",
        "        training_data = list(csv.reader(csvfile))[1 : ]\n",
        "\n",
        "    train_id = [int(data[0]) for data in training_data]\n",
        "\n",
        "    train_data = np.array([data[2 : ] for data in training_data])\n",
        "    train_data[train_data == ''] = np.nan\n",
        "    train_data = train_data.astype(float)\n",
        "\n",
        "    for data in training_data:\n",
        "        time_list = data[1].split(' ')\n",
        "        days_ago = int(time_list[0])\n",
        "\n",
        "        time = time_list[2].split(':')\n",
        "        hour, minute = int(time[0]), int(time[1])\n",
        "        train_time.append([days_ago, hour, minute])\n",
        "\n",
        "    return train_id, train_time, train_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2. preprocess the training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2122,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_incomplete_data(train_id: list, train_time: list, train_data: np.array) -> (list, list, np.array):\n",
        "    i = 0; train_nums = len(train_data)\n",
        "    while i < train_nums:\n",
        "        if np.sum(np.isnan(train_data[i])) >= 2:\n",
        "            train_data = np.delete(train_data, i, 0)\n",
        "            train_id.pop(i)\n",
        "            train_time.pop(i)\n",
        "            train_nums -= 1\n",
        "            i -= 1\n",
        "\n",
        "        if np.isnan(train_data[i][0]):\n",
        "            train_data[i][0] = train_data[i - 1][0]\n",
        "        elif np.isnan(train_data[i][1]):\n",
        "            train_data[i][1] = train_data[i - 1][1]\n",
        "        elif np.isnan(train_data[i][2]):\n",
        "            train_data[i][2] = train_data[i - 1][2]\n",
        "        elif np.isnan(train_data[i][3]):\n",
        "            train_data[i][3] = train_data[i - 1][3]\n",
        "\n",
        "        i += 1\n",
        "    return train_id, train_time, train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2123,
      "metadata": {},
      "outputs": [],
      "source": [
        "def divide_data(train_id: list, train_time: list, train_data: np.array) -> list:\n",
        "    ## We first divide the data into group by id\n",
        "    last_id = train_id[0]; group = []; tem_group = []\n",
        "    for i, data in enumerate(train_id):\n",
        "        tem_group.append(train_data[i])\n",
        "        if data != last_id:\n",
        "            group.append(tem_group)\n",
        "            tem_group = []\n",
        "            last_id = data\n",
        "    group.append(tem_group) # list-list-ndarray\n",
        "\n",
        "    ## Then we divide the data into group by time\n",
        "    new_group = []\n",
        "    for people in group:\n",
        "        morning, noon, afternoon, evening, night = [], [], [], [], []\n",
        "\n",
        "        for i in range(len(people)):\n",
        "            clock = train_time.pop(0)[1]\n",
        "            \n",
        "            if clock >= 6 and clock < 10:\n",
        "                morning.append([*train_data[i]])\n",
        "            elif clock >= 10 and clock < 14:\n",
        "                noon.append([*train_data[i]])\n",
        "            elif clock >= 14 and clock < 18:\n",
        "                afternoon.append([*train_data[i]])\n",
        "            elif clock >= 18 and clock < 22:\n",
        "                evening.append([*train_data[i]])\n",
        "            else:\n",
        "                night.append([*train_data[i]])\n",
        "        new_group.append([morning, noon, afternoon, evening, night])\n",
        "    return new_group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2124,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_outliers(group: list, width: float) -> list:\n",
        "    new_group = []\n",
        "\n",
        "    for people in group:\n",
        "        new_people = []\n",
        "\n",
        "        for time in people:\n",
        "            new_time = []\n",
        "\n",
        "            temperature = np.array([data[0] for data in time])\n",
        "            temperature_mean = np.mean(temperature); temperature_std = np.std(temperature)\n",
        "\n",
        "            heartrate = np.array([data[1] for data in time])\n",
        "            heartrate_mean = np.mean(heartrate); heartrate_std = np.std(heartrate)\n",
        "\n",
        "            resprate = np.array([data[2] for data in time])\n",
        "            resprate_mean = np.mean(resprate); resprate_std = np.std(resprate)\n",
        "\n",
        "            o2sat = np.array([data[3] for data in time])\n",
        "            o2sat_mean = np.mean(o2sat); o2sat_std = np.std(o2sat)\n",
        "\n",
        "            sbp = np.array([data[4] for data in time])\n",
        "            sbp_mean = np.mean(sbp); sbp_std = np.std(sbp)\n",
        "\n",
        "            temp_beyond_threshold = np.abs(temperature - temperature_mean) > width * temperature_std\n",
        "            heartrate_beyond_threshold = np.abs(heartrate - heartrate_mean) > width * heartrate_std\n",
        "            resprate_beyond_threshold = np.abs(resprate - resprate_mean) > width * resprate_std\n",
        "            o2sat_beyond_threshold = np.abs(o2sat - o2sat_mean) > width * o2sat_std\n",
        "            sbp_beyond_threshold = np.abs(sbp - sbp_mean) > width * sbp_std\n",
        "\n",
        "            for i in range(len(time)):\n",
        "                if temp_beyond_threshold[i] or heartrate_beyond_threshold[i] or resprate_beyond_threshold[i] or o2sat_beyond_threshold[i] or sbp_beyond_threshold[i]:\n",
        "                    continue\n",
        "                new_time.append(time[i])\n",
        "            new_people.append(time)\n",
        "        new_group.append(new_people)\n",
        "\n",
        "    return new_group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2125,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess(train_id: np.array, train_time: np.array, train_data: np.array, width: float) -> list:\n",
        "    '''\n",
        "    Assume the return value called list, then:\n",
        "        list: Whole data after preprocessing \\n\n",
        "        list[i]: Whole Data of the i-th person \\n\n",
        "        list[i][j]: Whole Data of the i-th person in the j-th time period \\n\n",
        "        list[i][j][k]: k-th Data of the i-th person in the j-th time period \\n\n",
        "        list[i][j][k][0]: Temperature of the k-th data of the i-th person in the j-th time period\n",
        "    '''\n",
        "    # remove the data with more than 2 elements missing\n",
        "    train_id, train_time, train_data = remove_incomplete_data(train_id, train_time, train_data)\n",
        "\n",
        "    # remove outliers\n",
        "    ## We first divide the data into group by id and time\n",
        "    group = divide_data(train_id, train_time, train_data)\n",
        "\n",
        "    ## Then we remove the data in each group once it has any outlier and return\n",
        "    return remove_outliers(group, width)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3. train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2126,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gradient_descent(y_ans: np.array, y_predict: np.array, x: np.array) -> np.array:\n",
        "    return (-2 * (y_ans - y_predict)).T.dot(x).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2127,
      "metadata": {},
      "outputs": [],
      "source": [
        "def Adam(gradient, coefficient, eta, m_t, v_t, n) -> np.array:\n",
        "    beta_1 = 0.9; beta_2 = 0.9; epsilon = 1e-7\n",
        "    m_t = beta_1 * m_t + (1 - beta_1) * gradient\n",
        "    v_t = beta_2 * v_t + (1 - beta_2) * (gradient ** 2)\n",
        "\n",
        "    m_hat = m_t / (1 - beta_1 ** n)\n",
        "    v_hat = v_t / (1 - beta_2 ** n)\n",
        "\n",
        "    return coefficient - eta * m_hat / (np.sqrt(v_hat) + epsilon)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2128,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(train_set: np.array, epoch: int, learning_rate: float, model: np.array) -> np.array:\n",
        "    '''\n",
        "    What I want to do: https://chat.openai.com/share/d4fa50cc-43d6-4651-93c7-9f42a8c49a3a\n",
        "    '''\n",
        "    eta = learning_rate\n",
        "    batch_nums = len(train_set)\n",
        "\n",
        "    plot_epoch = []; plot_train_MAPE = []; plot_validate_MAPE = []\n",
        "\n",
        "    MAPE_mean = 0\n",
        "    m_t = np.zeros((len(train_set[0][0]), 1)); v_t = np.zeros((len(train_set[0][0]), 1))\n",
        "    for e in range(epoch):\n",
        "        ith_validate = 0\n",
        "\n",
        "        validate_set = []; clean_train_set = []\n",
        "        for i ,batch in enumerate(train_set):\n",
        "            if i % batch_nums == ith_validate:\n",
        "                validate_set = batch\n",
        "                continue\n",
        "            \n",
        "            for datas in batch:\n",
        "                x = np.array([[1, *datas[ : -1]]]).astype(float)\n",
        "                y_ans = np.array([[datas[-1]]]).astype(float)\n",
        "                y_predict = x.dot(model).astype(int)\n",
        "\n",
        "                gradient = gradient_descent(y_ans, y_predict, x)\n",
        "                model = Adam(gradient, model, eta, m_t, v_t, i)\n",
        "\n",
        "            clean_train_set += batch\n",
        "            \n",
        "        validate_x = np.array([[1, *data[ : -1]] for data in validate_set]).astype(float)\n",
        "        validate_y = np.array([[data[-1]] for data in validate_set]).astype(float)\n",
        "        validate_y_prediction = validate_x.dot(model).astype(int)\n",
        "        MAPE_mean += MAPE(validate_y, validate_y_prediction)\n",
        "\n",
        "        clean_train_x = np.array([[1, *data[ : -1]] for data in clean_train_set]).astype(float)\n",
        "        clean_train_y = np.array([[data[-1]] for data in clean_train_set]).astype(float)\n",
        "        clean_train_y_prediction = clean_train_x.dot(model).astype(int)\n",
        "\n",
        "        plot_epoch.append(e + 1)\n",
        "        plot_validate_MAPE.append(MAPE(validate_y, validate_y_prediction))\n",
        "        plot_train_MAPE.append(MAPE(clean_train_y, clean_train_y_prediction))\n",
        "        \n",
        "    plt.plot(plot_epoch, plot_train_MAPE, 'blue')\n",
        "    plt.plot(plot_epoch, plot_validate_MAPE, 'red')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('MAPE')\n",
        "    plt.show()\n",
        "\n",
        "    print(f'MAPE = {MAPE_mean / epoch}')\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2129,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_2(datalist, epoch, learning_rate, model):\n",
        "    # random.shuffle(datalist)\n",
        "    nums = len(datalist)\n",
        "    train_set = datalist[ : int(nums * 0.8)]\n",
        "    validate_set = datalist[int(nums * 0.8) : ]\n",
        "\n",
        "    eta = learning_rate\n",
        "    plot_epoch = []; plot_train_MAPE = []; plot_validate_MAPE = []\n",
        "\n",
        "    m_t = np.zeros((len(train_set[0]), 1)); v_t = np.zeros((len(train_set[0]), 1))\n",
        "    for i, data in enumerate(train_set):\n",
        "        x = np.array([[1, *data[ : -1]]]).astype(float)\n",
        "        y_ans = np.array([[data[-1]]]).astype(float)\n",
        "        y_predict = x.dot(model).astype(int)\n",
        "\n",
        "        gradient = gradient_descent(y_ans, y_predict, x)\n",
        "        model = Adam(gradient, model, eta, m_t, v_t, i + 1)\n",
        "\n",
        "        plot_epoch.append(i + 1)\n",
        "        plot_train_MAPE.append(MAPE(y_ans, y_predict))\n",
        "\n",
        "    validate_x = np.array([[1, *data[ : -1]] for data in validate_set]).astype(float)\n",
        "    validate_y = np.array([[data[-1]] for data in validate_set]).astype(float)\n",
        "    validate_y_prediction = validate_x.dot(model).astype(int)\n",
        "    print(f'MAPE = {MAPE(validate_y, validate_y_prediction)}')\n",
        "\n",
        "    plt.plot(plot_epoch, plot_train_MAPE, 'blue')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('MAPE')\n",
        "    plt.show()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2130,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAPE = 12.895396788095395\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[24.62673921]\n",
            " [ 0.1267392 ]\n",
            " [ 0.7767392 ]\n",
            " [ 0.1267392 ]\n",
            " [ 0.4267392 ]]\n"
          ]
        }
      ],
      "source": [
        "train_set = preprocess(*read_data(), 2)\n",
        "\n",
        "people_nums = len(train_set)\n",
        "morning_train_set = [train_set[i][0] for i in range(people_nums)]\n",
        "noon_train_set = [train_set[i][1] for i in range(people_nums)]\n",
        "afternoon_train_set = [train_set[i][2] for i in range(people_nums)]\n",
        "evening_train_set = [train_set[i][3] for i in range(people_nums)]\n",
        "night_train_set = [train_set[i][4] for i in range(people_nums)]\n",
        "\n",
        "a = []\n",
        "for time in train_set:\n",
        "    for people in morning_train_set:\n",
        "        for data in people:\n",
        "            a.append(data)\n",
        "\n",
        "a_model = np.array([[25], [0.5], [1.15], [0.5], [0.8]]).astype(float)\n",
        "a_model = train_2(a, 100, 0.0025, a_model)\n",
        "print(a_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2131,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train_set = preprocess(*read_data(), 2.5)\n",
        "\n",
        "# people_nums = len(train_set)\n",
        "# morning_train_set = [train_set[i][0] for i in range(people_nums)]\n",
        "# noon_train_set = [train_set[i][1] for i in range(people_nums)]\n",
        "# afternoon_train_set = [train_set[i][2] for i in range(people_nums)]\n",
        "# evening_train_set = [train_set[i][3] for i in range(people_nums)]\n",
        "# night_train_set = [train_set[i][4] for i in range(people_nums)]\n",
        "\n",
        "# morning_model = np.array([[5], [-0.2], [1], [0.25], [1]]).astype(float) # const, temperature, heartrate, resprate, o2sat\n",
        "# morning_model = train(morning_train_set, len(morning_train_set) * 25, 0.00005, morning_model)\n",
        "# print(*morning_model)\n",
        "# print('-' * 80)\n",
        "\n",
        "# noon_model = np.array([[5], [-0.2], [1], [0.25], [1]]).astype(float)\n",
        "# noon_model = train(noon_train_set, len(noon_train_set) * 20, 0.001, noon_model)\n",
        "# print(*noon_model)\n",
        "# print('-' * 80)\n",
        "\n",
        "# afternoon_model = np.array([[5], [-0.2], [1], [0.25], [1]]).astype(float)\n",
        "# afternoon_model = train(afternoon_train_set, len(afternoon_train_set) * 20, 0.001, afternoon_model)\n",
        "# print(*afternoon_model)\n",
        "# print('-' * 80)\n",
        "\n",
        "# evening_model = np.array([[5], [-0.2], [1], [0.25], [1]]).astype(float)\n",
        "# evening_model = train(evening_train_set, len(evening_train_set) * 20, 0.001, evening_model)\n",
        "# print(*evening_model)\n",
        "# print('-' * 80)\n",
        "\n",
        "# night_model = np.array([[5], [-0.2], [1], [0.25], [1]]).astype(float)\n",
        "# night_model = train(night_train_set, len(night_train_set) * 20, 0.001, night_model)\n",
        "# print(*night_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Output your Prediction\n",
        "\n",
        "> your filename should be **hw1_advanced.csv**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2132,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(output_dataroot, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
        "  writer = csv.writer(csvfile)\n",
        "  for row in output_datalist:\n",
        "    writer.writerow(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtgCJU7FPeJL"
      },
      "source": [
        "# Report *(5%)*\n",
        "\n",
        "Report should be submitted as a pdf file **hw1_report.pdf**\n",
        "\n",
        "*   Briefly describe the difficulty you encountered\n",
        "*   Summarize your work and your reflections\n",
        "*   No more than one page\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlEE53_MPf4W"
      },
      "source": [
        "# Save the Code File\n",
        "Please save your code and submit it as an ipynb file! (**hw1.ipynb**)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_Te27fi-0pP"
      },
      "source": [
        "# **HW1: Regression**\n",
        "In *assignment 1*, you need to finish:\n",
        "\n",
        "1.  Basic Part: Implement two regression models to predict the Systolic blood pressure (SBP) of a patient. You will need to implement **both Matrix Inversion and Gradient Descent**.\n",
        "\n",
        "\n",
        "> *   Step 1: Split Data\n",
        "> *   Step 2: Preprocess Data\n",
        "> *   Step 3: Implement Regression\n",
        "> *   Step 4: Make Prediction\n",
        "> *   Step 5: Train Model and Generate Result\n",
        "\n",
        "2.  Advanced Part: Implement one regression model to predict the SBP of multiple patients in a different way than the basic part. You can choose **either** of the two methods for this part."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wDdnos-4uUv"
      },
      "source": [
        "# **1. Basic Part (55%)**\n",
        "In the first part, you need to implement the regression to predict SBP from the given DBP\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_EVqWlB-DTF"
      },
      "source": [
        "## 1.1 Matrix Inversion Method (25%)\n",
        "\n",
        "\n",
        "*   Save the prediction result in a csv file **hw1_basic_mi.csv**\n",
        "*   Print your coefficient\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzCR7vk9BFkf"
      },
      "source": [
        "### *Import Packages*\n",
        "\n",
        "> Note: You **cannot** import any other package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3776,
      "metadata": {
        "id": "HL5XjqFf4wSj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import csv\n",
        "import math\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnWjrzi0dMPz"
      },
      "source": [
        "### *Global attributes*\n",
        "Define the global attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3777,
      "metadata": {
        "id": "EWLDPOlHBbcK"
      },
      "outputs": [],
      "source": [
        "training_dataroot = 'hw1_basic_training.csv' # Training data file file named as 'hw1_basic_training.csv'\n",
        "testing_dataroot = 'hw1_basic_testing.csv'   # Testing data file named as 'hw1_basic_training.csv'\n",
        "output_dataroot = 'hw1_basic_mi.csv' # Output file will be named as 'hw1_basic.csv'\n",
        "\n",
        "training_datalist =  [] # Training datalist, saved as numpy array\n",
        "testing_datalist =  [] # Testing datalist, saved as numpy array\n",
        "\n",
        "output_datalist =  [] # Your prediction, should be 20 * 1 matrix and saved as numpy array\n",
        "                      # The format of each row should be ['sbp']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsFC-cvqIcYK"
      },
      "source": [
        "You can add your own global attributes here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3778,
      "metadata": {
        "id": "OUbS2BEgcut6"
      },
      "outputs": [],
      "source": [
        "def MAPE(y_ans, y_prediction):\n",
        "    return np.mean(np.abs((y_ans - y_prediction) / y_ans)) * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUoRFoQjBW5S"
      },
      "source": [
        "### *Load the Input File*\n",
        "First, load the basic input file **hw1_basic_training.csv** and **hw1_basic_testing.csv**\n",
        "\n",
        "Input data would be stored in *training_datalist* and *testing_datalist*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3779,
      "metadata": {
        "id": "dekR1KnqBtI6"
      },
      "outputs": [],
      "source": [
        "# Read input csv to datalist\n",
        "with open(training_dataroot, newline='') as csvfile:\n",
        "    training_datalist = np.array(list(csv.reader(csvfile)))\n",
        "    training_datalist = np.delete(training_datalist, 0, 0)\n",
        "\n",
        "with open(testing_dataroot, newline='') as csvfile:\n",
        "    testing_datalist = np.array(list(csv.reader(csvfile)))\n",
        "    testing_datalist = np.delete(testing_datalist, 0, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kYPuikLCFx4"
      },
      "source": [
        "### *Implement the Regression Model*\n",
        "\n",
        "> Note: It is recommended to use the functions we defined, you can also define your own functions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWwdx06JNEYs"
      },
      "source": [
        "#### Step 1: Split Data\n",
        "Split data in *training_datalist* into training dataset and validation dataset\n",
        "* Validation dataset is used to validate your own model without the testing data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3780,
      "metadata": {
        "id": "USDciENcB-5F"
      },
      "outputs": [],
      "source": [
        "def split_data(training_datalist: np.array) -> (np.array, np.array):\n",
        "    train_nums = int(len(training_datalist) * 0.8)\n",
        "    return training_datalist[ : train_nums], training_datalist[train_nums : ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-3Qln4aNgVy"
      },
      "source": [
        "#### Step 2: Preprocess Data\n",
        "Handle the unreasonable data\n",
        "> Hint: Outlier and missing data can be handled by removing the data or adding the values with the help of statistics  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3781,
      "metadata": {
        "id": "XXvW1n_5NkQ5"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(training_datalist: np.array, boundary: int) -> np.array:\n",
        "    train_nums = len(training_datalist)\n",
        "\n",
        "    dbp = np.array([[data[0]] for data in training_datalist]).astype(float)\n",
        "    sbp = np.array([[data[1]] for data in training_datalist]).astype(float)\n",
        "\n",
        "    dbp_mean = np.mean(dbp)\n",
        "    dbp_std = np.std(dbp)\n",
        "    sbp_mean = np.mean(sbp)\n",
        "    sbp_std = np.std(sbp)\n",
        "\n",
        "    i = -1\n",
        "    while i < train_nums - 1:\n",
        "        i += 1\n",
        "\n",
        "        dbp_below_threshold = dbp[i] < dbp_mean - boundary * dbp_std\n",
        "        dbp_above_threshold = dbp[i] > dbp_mean + boundary * dbp_std\n",
        "        sbp_below_threshold = sbp[i] < sbp_mean - boundary * sbp_std\n",
        "        sbp_above_threshold = sbp[i] > sbp_mean + boundary * sbp_std\n",
        "\n",
        "        if (dbp_below_threshold or dbp_above_threshold) or (sbp_below_threshold or sbp_above_threshold):\n",
        "            training_datalist = np.delete(training_datalist, i, 0)\n",
        "            train_nums -= 1\n",
        "            i -= 1\n",
        "\n",
        "    return training_datalist.astype(float)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDLpJmQUN3V6"
      },
      "source": [
        "#### Step 3: Implement Regression\n",
        "> use Matrix Inversion to finish this part\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3782,
      "metadata": {
        "id": "Tx9n1_23N8C0"
      },
      "outputs": [],
      "source": [
        "def matrix_inversion(train_set: np.array) -> np.array:\n",
        "    x = np.array([[1, data[0]] for data in train_set]).astype(float)\n",
        "    y_ans = np.array([[data[1]] for data in train_set]).astype(float)\n",
        "    return np.linalg.inv(x.T.dot(x)).dot(x.T).dot(y_ans)\n",
        "\n",
        "def validation(validate_set: np.array, coefficient: np.array) -> str:\n",
        "    validate_x = np.array([[1, data[0]] for data in validate_set])\n",
        "    validate_y = np.array([[data[1]] for data in validate_set])\n",
        "    validate_y_prediction = validate_x.dot(coefficient).astype(int)\n",
        "    return f'MAPE of validation set : {MAPE(validate_y, validate_y_prediction)}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NxRNFwyN8xd"
      },
      "source": [
        "#### Step 4: Make Prediction\n",
        "Make prediction of testing dataset and store the value in *output_datalist*\n",
        "The final *output_datalist* should look something like this \n",
        "> [ [100], [80], ... , [90] ] where each row contains the predicted SBP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3783,
      "metadata": {
        "id": "EKlDIC2-N_lk"
      },
      "outputs": [],
      "source": [
        "def make_prediction(testing_datalist: np.array, coefficient: np.array) -> np.array:\n",
        "    testing_x = np.array([[1, data[0]] for data in testing_datalist]).astype(float)\n",
        "    return testing_x.dot(coefficient).astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCd0Z6izOCwq"
      },
      "source": [
        "#### Step 5: Train Model and Generate Result\n",
        "\n",
        "> Notice: **Remember to output the coefficients of the model here**, otherwise 5 points would be deducted\n",
        "* If your regression model is *3x^2 + 2x^1 + 1*, your output would be:\n",
        "```\n",
        "3 2 1\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3784,
      "metadata": {
        "id": "iCL92EPKOFIn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAPE of validation set : 5.000690216635821\n",
            "\n",
            "---------- Coefficient ----------\n",
            "0.9210072989326239 52.277057839995386 "
          ]
        }
      ],
      "source": [
        "train, validate = split_data(preprocess_data(training_datalist, 2))\n",
        "coefficient = matrix_inversion(train)\n",
        "output_datalist = make_prediction(testing_datalist, coefficient)\n",
        "\n",
        "print(validation(validate, coefficient))\n",
        "print('\\n' + '-' * 10 + ' Coefficient ' + '-' * 10)\n",
        "\n",
        "for coe in coefficient[::-1]:\n",
        "    print(coe[0], end = ' ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8Jhd8wAOk3D"
      },
      "source": [
        "### *Write the Output File*\n",
        "Write the prediction to output csv\n",
        "> Format: 'sbp'\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3785,
      "metadata": {
        "id": "tYQVYLlKOtDB"
      },
      "outputs": [],
      "source": [
        "with open(output_dataroot, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
        "\twriter = csv.writer(csvfile)\n",
        "\tfor row in output_datalist:\n",
        "\t\twriter.writerow(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1J3WOhglA9ML"
      },
      "source": [
        "## 1.2 Gradient Descent Method (30%)\n",
        "\n",
        "\n",
        "*   Save the prediction result in a csv file **hw1_basic_gd.csv**\n",
        "*   Output your coefficient update in a csv file **hw1_basic_coefficient.csv**\n",
        "*   Print your coefficient\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkMqa_xjXhEv"
      },
      "source": [
        "### *Global attributes*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3786,
      "metadata": {
        "id": "wNZtRWUeXpEu"
      },
      "outputs": [],
      "source": [
        "output_dataroot = 'hw1_basic_gd.csv' # Output file will be named as 'hw1_basic.csv'\n",
        "coefficient_output_dataroot = 'hw1_basic_coefficient.csv'\n",
        "\n",
        "training_datalist =  [] # Training datalist, saved as numpy array\n",
        "testing_datalist =  [] # Testing datalist, saved as numpy array\n",
        "\n",
        "output_datalist =  [] # Your prediction, should be 20 * 1 matrix and saved as numpy array\n",
        "                      # The format of each row should be ['sbp']\n",
        "\n",
        "coefficient_output = [] # Your coefficient update during gradient descent\n",
        "                   # Should be a (number of iterations * number_of coefficient) matrix\n",
        "                   # The format of each row should be ['w0', 'w1', ...., 'wn']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5DeHxdLdai3"
      },
      "source": [
        "Your own global attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3787,
      "metadata": {
        "id": "_2IO5tYSdaFd"
      },
      "outputs": [],
      "source": [
        "# Read input csv to datalist\n",
        "with open(training_dataroot, newline='') as csvfile:\n",
        "    training_datalist = np.array(list(csv.reader(csvfile)))\n",
        "    training_datalist = np.delete(training_datalist, 0, 0)\n",
        "\n",
        "with open(testing_dataroot, newline='') as csvfile:\n",
        "    testing_datalist = np.array(list(csv.reader(csvfile)))\n",
        "    testing_datalist = np.delete(testing_datalist, 0, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVBLT1aqXuW0"
      },
      "source": [
        "### *Implement the Regression Model*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecPWpcOnXhCZ"
      },
      "source": [
        "#### Step 1: Split Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3788,
      "metadata": {
        "id": "1PEf_qGvYHu0"
      },
      "outputs": [],
      "source": [
        "def split_data(training_datalist: np.array) -> (np.array, np.array):\n",
        "    train_nums = int(len(training_datalist) * 0.8)\n",
        "    return training_datalist[ : train_nums], training_datalist[train_nums : ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpSoPDPKX56w"
      },
      "source": [
        "#### Step 2: Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3789,
      "metadata": {
        "id": "uLTXOWRwYHiS"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(training_datalist: np.array, width: float) -> np.array:\n",
        "    train_nums = len(training_datalist)\n",
        "\n",
        "    dbp = np.array([[data[0]] for data in training_datalist]).astype(float)\n",
        "    sbp = np.array([[data[1]] for data in training_datalist]).astype(float)\n",
        "\n",
        "    dbp_mean = np.mean(dbp)\n",
        "    dbp_std = np.std(dbp)\n",
        "    sbp_mean = np.mean(sbp)\n",
        "    sbp_std = np.std(sbp)\n",
        "\n",
        "    i = -1\n",
        "    while i < train_nums - 1:\n",
        "        i += 1\n",
        "\n",
        "        dbp_below_threshold = dbp[i] < dbp_mean - width * dbp_std\n",
        "        dbp_above_threshold = dbp[i] > dbp_mean + width * dbp_std\n",
        "        sbp_below_threshold = sbp[i] < sbp_mean - width * sbp_std\n",
        "        sbp_above_threshold = sbp[i] > sbp_mean + width * sbp_std\n",
        "\n",
        "        if (dbp_below_threshold or dbp_above_threshold) or (sbp_below_threshold or sbp_above_threshold):\n",
        "            training_datalist = np.delete(training_datalist, i, 0)\n",
        "            train_nums -= 1\n",
        "            i -= 1\n",
        "\n",
        "    return training_datalist.astype(float)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TV_y82gXX6a-"
      },
      "source": [
        "#### Step 3: Implement Regression\n",
        "> use Gradient Descent to finish this part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3790,
      "metadata": {
        "id": "-635Ee00YHTE"
      },
      "outputs": [],
      "source": [
        "def gradient_descent(epoch: int, learning_rate: float, train_set: np.array) -> np.array:\n",
        "    def gradient_of_loss(y_ans: np.array, y_predict: np.array, x: np.array) -> np.array: \n",
        "        return (-2 * (y_ans - y_predict)).T.dot(x).T\n",
        "    \n",
        "    coefficient = np.array([[50], [0.9]]).astype(float)\n",
        "    x = np.array([[1, data[0]] for data in train_set]).astype(float)\n",
        "    y_ans = np.array([[data[1]] for data in train_set]).astype(float)\n",
        "    y_predict = x.dot(coefficient).astype(float)\n",
        "\n",
        "    for e in range(epoch):\n",
        "        coefficient -= learning_rate * gradient_of_loss(y_ans, y_predict, x)\n",
        "        y_predict = x.dot(coefficient)\n",
        "        coefficient_output.append(coefficient[::-1])\n",
        "        print(f'Epoch {e + 1:2} : MAPE = {MAPE(y_ans, y_predict)}')\n",
        "    \n",
        "    return coefficient\n",
        "    \n",
        "def validation(validate_set: np.array, coefficient: np.array) -> str:\n",
        "    validate_x = np.array([[1, data[0]] for data in validate_set])\n",
        "    validate_y = np.array([[data[1]] for data in validate_set])\n",
        "    validate_y_prediction = validate_x.dot(coefficient).astype(int)\n",
        "    return f'MAPE of validation set : {MAPE(validate_y, validate_y_prediction)}'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLuPxs2ZX21S"
      },
      "source": [
        "#### Step 4: Make Prediction\n",
        "\n",
        "Make prediction of testing dataset and store the values in *output_datalist*\n",
        "The final *output_datalist* should look something like this \n",
        "> [ [100], [80], ... , [90] ] where each row contains the predicted SBP\n",
        "\n",
        "Remember to also store your coefficient update in *coefficient_output*\n",
        "The final *coefficient_output* should look something like this\n",
        "> [ [1, 0, 3, 5], ... , [0.1, 0.3, 0.2, 0.5] ] where each row contains the [w0, w1, ..., wn] of your coefficient\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3791,
      "metadata": {
        "id": "8pnNDlQeYGtE"
      },
      "outputs": [],
      "source": [
        "def make_prediction(testing_datalist: np.array, coefficient: np.array) -> np.array:\n",
        "    testing_x = np.array([[1, data[0]] for data in testing_datalist]).astype(float)\n",
        "    return testing_x.dot(coefficient).astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IScbxxMAYAgZ"
      },
      "source": [
        "#### Step 5: Train Model and Generate Result\n",
        "\n",
        "> Notice: **Remember to output the coefficients of the model here**, otherwise 5 points would be deducted\n",
        "* If your regression model is *3x^2 + 2x^1 + 1*, your output would be:\n",
        "```\n",
        "3 2 1\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3792,
      "metadata": {
        "id": "90EisOc7YG-N"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch  1 : MAPE = 4.8884711898988344\n",
            "Epoch  2 : MAPE = 4.92717997279329\n",
            "Epoch  3 : MAPE = 4.943203113903013\n",
            "Epoch  4 : MAPE = 4.9476709834159145\n",
            "Epoch  5 : MAPE = 4.948830525460115\n",
            "Epoch  6 : MAPE = 4.949120445821383\n",
            "Epoch  7 : MAPE = 4.94919295082846\n",
            "Epoch  8 : MAPE = 4.949211099513473\n",
            "Epoch  9 : MAPE = 4.949215658497023\n",
            "Epoch 10 : MAPE = 4.949216819899923\n",
            "Epoch 11 : MAPE = 4.949217131868798\n",
            "Epoch 12 : MAPE = 4.9492172314694125\n",
            "Epoch 13 : MAPE = 4.9492172779754835\n",
            "Epoch 14 : MAPE = 4.949217311207263\n",
            "Epoch 15 : MAPE = 4.949217341120262\n",
            "Epoch 16 : MAPE = 4.949217370203477\n",
            "Epoch 17 : MAPE = 4.949217399079183\n",
            "Epoch 18 : MAPE = 4.949217427902959\n",
            "Epoch 19 : MAPE = 4.949217456713698\n",
            "Epoch 20 : MAPE = 4.949217485521125\n",
            "Epoch 21 : MAPE = 4.949217514327674\n",
            "Epoch 22 : MAPE = 4.949217543133948\n",
            "Epoch 23 : MAPE = 4.9492175719401015\n",
            "Epoch 24 : MAPE = 4.949217600746173\n",
            "Epoch 25 : MAPE = 4.949217629552173\n",
            "Epoch 26 : MAPE = 4.949217658358101\n",
            "Epoch 27 : MAPE = 4.949217687163961\n",
            "Epoch 28 : MAPE = 4.949217715969748\n",
            "Epoch 29 : MAPE = 4.949217744775466\n",
            "Epoch 30 : MAPE = 4.9492177735811165\n",
            "Epoch 31 : MAPE = 4.949217802386697\n",
            "Epoch 32 : MAPE = 4.949217831192207\n",
            "Epoch 33 : MAPE = 4.9492178599976455\n",
            "Epoch 34 : MAPE = 4.949217888803017\n",
            "Epoch 35 : MAPE = 4.949217917608316\n",
            "Epoch 36 : MAPE = 4.949217946413546\n",
            "Epoch 37 : MAPE = 4.9492179752187075\n",
            "Epoch 38 : MAPE = 4.949218004023799\n",
            "Epoch 39 : MAPE = 4.949218032828819\n",
            "Epoch 40 : MAPE = 4.949218061633771\n",
            "Epoch 41 : MAPE = 4.949218090438652\n",
            "Epoch 42 : MAPE = 4.949218119243463\n",
            "Epoch 43 : MAPE = 4.949218148048207\n",
            "Epoch 44 : MAPE = 4.949218176852878\n",
            "Epoch 45 : MAPE = 4.949218205657482\n",
            "Epoch 46 : MAPE = 4.949218234462012\n",
            "Epoch 47 : MAPE = 4.949218263266475\n",
            "Epoch 48 : MAPE = 4.949218292070869\n",
            "Epoch 49 : MAPE = 4.949218320875193\n",
            "Epoch 50 : MAPE = 4.949218349679445\n",
            "Epoch 51 : MAPE = 4.9492183784836286\n",
            "Epoch 52 : MAPE = 4.949218407287743\n",
            "Epoch 53 : MAPE = 4.949218436091788\n",
            "Epoch 54 : MAPE = 4.949218464895762\n",
            "Epoch 55 : MAPE = 4.949218493699666\n",
            "Epoch 56 : MAPE = 4.949218522503502\n",
            "Epoch 57 : MAPE = 4.949218551307264\n",
            "Epoch 58 : MAPE = 4.949218580110961\n",
            "Epoch 59 : MAPE = 4.949218608914588\n",
            "Epoch 60 : MAPE = 4.949218637718145\n",
            "Epoch 61 : MAPE = 4.94921866652163\n",
            "Epoch 62 : MAPE = 4.949218695325044\n",
            "Epoch 63 : MAPE = 4.949218724128393\n",
            "Epoch 64 : MAPE = 4.949218752931668\n",
            "Epoch 65 : MAPE = 4.949218781734875\n",
            "Epoch 66 : MAPE = 4.949218810538011\n",
            "Epoch 67 : MAPE = 4.9492188393410785\n",
            "Epoch 68 : MAPE = 4.949218868144076\n",
            "Epoch 69 : MAPE = 4.949218896947006\n",
            "Epoch 70 : MAPE = 4.94921892574986\n",
            "Epoch 71 : MAPE = 4.9492189545526495\n",
            "Epoch 72 : MAPE = 4.949218983355367\n",
            "Epoch 73 : MAPE = 4.949219012158015\n",
            "Epoch 74 : MAPE = 4.949219040960596\n",
            "Epoch 75 : MAPE = 4.949219069763104\n",
            "Epoch 76 : MAPE = 4.949219098565543\n",
            "Epoch 77 : MAPE = 4.949219127367913\n",
            "Epoch 78 : MAPE = 4.949219156170212\n",
            "Epoch 79 : MAPE = 4.949219184972443\n",
            "Epoch 80 : MAPE = 4.9492192137746\n",
            "Epoch 81 : MAPE = 4.949219242576692\n",
            "Epoch 82 : MAPE = 4.949219271378713\n",
            "Epoch 83 : MAPE = 4.949219300180663\n",
            "Epoch 84 : MAPE = 4.949219328982545\n",
            "Epoch 85 : MAPE = 4.949219357784356\n",
            "Epoch 86 : MAPE = 4.949219386586097\n",
            "Epoch 87 : MAPE = 4.949219415387769\n",
            "Epoch 88 : MAPE = 4.949219444189372\n",
            "Epoch 89 : MAPE = 4.949219472990904\n",
            "Epoch 90 : MAPE = 4.949219501792364\n",
            "Epoch 91 : MAPE = 4.949219530593758\n",
            "Epoch 92 : MAPE = 4.949219559395079\n",
            "Epoch 93 : MAPE = 4.949219588196334\n",
            "Epoch 94 : MAPE = 4.949219616997515\n",
            "Epoch 95 : MAPE = 4.94921964579863\n",
            "Epoch 96 : MAPE = 4.949219674599672\n",
            "Epoch 97 : MAPE = 4.949219703400646\n",
            "Epoch 98 : MAPE = 4.949219732201552\n",
            "Epoch 99 : MAPE = 4.949219761002386\n",
            "Epoch 100 : MAPE = 4.94921978980315\n",
            "Epoch 101 : MAPE = 4.949219818603845\n",
            "Epoch 102 : MAPE = 4.94921984740447\n",
            "Epoch 103 : MAPE = 4.949219876205024\n",
            "Epoch 104 : MAPE = 4.949219905005511\n",
            "Epoch 105 : MAPE = 4.949219933805925\n",
            "Epoch 106 : MAPE = 4.949219962606271\n",
            "Epoch 107 : MAPE = 4.949219991406548\n",
            "Epoch 108 : MAPE = 4.949220020206755\n",
            "Epoch 109 : MAPE = 4.949220049006891\n",
            "Epoch 110 : MAPE = 4.949220077806958\n",
            "Epoch 111 : MAPE = 4.949220106606955\n",
            "Epoch 112 : MAPE = 4.949220135406881\n",
            "Epoch 113 : MAPE = 4.94922016420674\n",
            "Epoch 114 : MAPE = 4.949220193006527\n",
            "Epoch 115 : MAPE = 4.949220221806244\n",
            "Epoch 116 : MAPE = 4.949220250605895\n",
            "Epoch 117 : MAPE = 4.949220279405471\n",
            "Epoch 118 : MAPE = 4.949220308204978\n",
            "Epoch 119 : MAPE = 4.9492203370044185\n",
            "Epoch 120 : MAPE = 4.949220365803787\n",
            "Epoch 121 : MAPE = 4.949220394603087\n",
            "Epoch 122 : MAPE = 4.949220423402316\n",
            "Epoch 123 : MAPE = 4.949220452201477\n",
            "Epoch 124 : MAPE = 4.949220481000566\n",
            "Epoch 125 : MAPE = 4.949220509799587\n",
            "Epoch 126 : MAPE = 4.949220538598538\n",
            "Epoch 127 : MAPE = 4.949220567397416\n",
            "Epoch 128 : MAPE = 4.949220596196229\n",
            "Epoch 129 : MAPE = 4.949220624994971\n",
            "Epoch 130 : MAPE = 4.949220653793642\n",
            "Epoch 131 : MAPE = 4.949220682592244\n",
            "Epoch 132 : MAPE = 4.949220711390774\n",
            "Epoch 133 : MAPE = 4.9492207401892365\n",
            "Epoch 134 : MAPE = 4.9492207689876295\n",
            "Epoch 135 : MAPE = 4.9492207977859515\n",
            "Epoch 136 : MAPE = 4.949220826584204\n",
            "Epoch 137 : MAPE = 4.9492208553823875\n",
            "Epoch 138 : MAPE = 4.9492208841805\n",
            "Epoch 139 : MAPE = 4.949220912978544\n",
            "Epoch 140 : MAPE = 4.949220941776518\n",
            "Epoch 141 : MAPE = 4.949220970574421\n",
            "Epoch 142 : MAPE = 4.949220999372255\n",
            "Epoch 143 : MAPE = 4.949221028170021\n",
            "Epoch 144 : MAPE = 4.949221056967714\n",
            "Epoch 145 : MAPE = 4.9492210857653385\n",
            "Epoch 146 : MAPE = 4.949221114562895\n",
            "Epoch 147 : MAPE = 4.949221143360381\n",
            "Epoch 148 : MAPE = 4.949221172157795\n",
            "Epoch 149 : MAPE = 4.949221200955142\n",
            "Epoch 150 : MAPE = 4.949221229752416\n",
            "Epoch 151 : MAPE = 4.949221258549622\n",
            "Epoch 152 : MAPE = 4.949221287346759\n",
            "Epoch 153 : MAPE = 4.949221316143825\n",
            "Epoch 154 : MAPE = 4.949221344940823\n",
            "Epoch 155 : MAPE = 4.9492213737377515\n",
            "Epoch 156 : MAPE = 4.949221402534608\n",
            "Epoch 157 : MAPE = 4.949221431331397\n",
            "Epoch 158 : MAPE = 4.949221460128113\n",
            "Epoch 159 : MAPE = 4.949221488924761\n",
            "Epoch 160 : MAPE = 4.949221517721339\n",
            "Epoch 161 : MAPE = 4.9492215465178475\n",
            "Epoch 162 : MAPE = 4.949221575314288\n",
            "Epoch 163 : MAPE = 4.949221604110659\n",
            "Epoch 164 : MAPE = 4.949221632906955\n",
            "Epoch 165 : MAPE = 4.949221661703184\n",
            "Epoch 166 : MAPE = 4.949221690499344\n",
            "Epoch 167 : MAPE = 4.949221719295434\n",
            "Epoch 168 : MAPE = 4.949221748091456\n",
            "Epoch 169 : MAPE = 4.949221776887405\n",
            "Epoch 170 : MAPE = 4.949221805683286\n",
            "Epoch 171 : MAPE = 4.949221834479096\n",
            "Epoch 172 : MAPE = 4.94922186327484\n",
            "Epoch 173 : MAPE = 4.949221892070509\n",
            "Epoch 174 : MAPE = 4.949221920866111\n",
            "Epoch 175 : MAPE = 4.949221949661643\n",
            "Epoch 176 : MAPE = 4.949221978457105\n",
            "Epoch 177 : MAPE = 4.949222007252498\n",
            "Epoch 178 : MAPE = 4.94922203604782\n",
            "Epoch 179 : MAPE = 4.949222064843073\n",
            "Epoch 180 : MAPE = 4.949222093638255\n",
            "Epoch 181 : MAPE = 4.94922212243337\n",
            "Epoch 182 : MAPE = 4.949222151228412\n",
            "Epoch 183 : MAPE = 4.949222180023387\n",
            "Epoch 184 : MAPE = 4.94922220881829\n",
            "Epoch 185 : MAPE = 4.949222237613125\n",
            "Epoch 186 : MAPE = 4.949222266407889\n",
            "Epoch 187 : MAPE = 4.949222295202584\n",
            "Epoch 188 : MAPE = 4.949222323997208\n",
            "Epoch 189 : MAPE = 4.9492223527917645\n",
            "Epoch 190 : MAPE = 4.949222381586249\n",
            "Epoch 191 : MAPE = 4.949222410380667\n",
            "Epoch 192 : MAPE = 4.9492224391750135\n",
            "Epoch 193 : MAPE = 4.949222467969289\n",
            "Epoch 194 : MAPE = 4.949222496763495\n",
            "Epoch 195 : MAPE = 4.94922252555763\n",
            "Epoch 196 : MAPE = 4.949222554351697\n",
            "Epoch 197 : MAPE = 4.949222583145694\n",
            "Epoch 198 : MAPE = 4.949222611939621\n",
            "Epoch 199 : MAPE = 4.94922264073348\n",
            "Epoch 200 : MAPE = 4.949222669527267\n",
            "\n",
            "---------- MAPE ----------\n",
            "MAPE of validation set : 4.9843450987673075\n",
            "\n",
            "---------- Coefficient ----------\n",
            "0.9486378390461381 50.00169355057738 "
          ]
        }
      ],
      "source": [
        "train, validate = split_data(preprocess_data(training_datalist, 2))\n",
        "coefficient = gradient_descent(200, 0.0000005, train)\n",
        "output_datalist = make_prediction(testing_datalist, coefficient)\n",
        "\n",
        "print('\\n' + '-' * 10 + ' MAPE ' + '-' * 10)\n",
        "print(validation(validate, coefficient))\n",
        "print('\\n' + '-' * 10 + ' Coefficient ' + '-' * 10)\n",
        "\n",
        "for coe in coefficient[::-1]:\n",
        "    print(coe[0], end = ' ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1DpV_HcYFpl"
      },
      "source": [
        "### *Write the Output File*\n",
        "\n",
        "Write the prediction to output csv\n",
        "> Format: 'sbp'\n",
        "\n",
        "**Write the coefficient update to csv**\n",
        "> Format: 'w0', 'w1', ..., 'wn'\n",
        ">*   The number of columns is based on your number of coefficient\n",
        ">*   The number of row is based on your number of iterations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3793,
      "metadata": {
        "id": "NLSHgpDvDXNI"
      },
      "outputs": [],
      "source": [
        "with open(output_dataroot, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
        "\twriter = csv.writer(csvfile)\n",
        "\tfor row in output_datalist:\n",
        "\t\twriter.writerow(row)\n",
        "\n",
        "with open(coefficient_output_dataroot, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
        "\twriter = csv.writer(csvfile)\n",
        "\tfor row in coefficient_output:\n",
        "\t\twriter.writerow(row.flatten())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rx4408qg4xMQ"
      },
      "source": [
        "# **2. Advanced Part (40%)**\n",
        "In the second part, you need to implement the regression in a different way than the basic part to help your predictions of multiple patients SBP.\n",
        "\n",
        "You can choose **either** Matrix Inversion or Gradient Descent method.\n",
        "\n",
        "The training data will be in **hw1_advanced_training.csv** and the testing data will be in **hw1_advanced_testing.csv**.\n",
        "\n",
        "Output your prediction in **hw1_advanced.csv**\n",
        "\n",
        "Notice:\n",
        "> You cannot import any other package other than those given\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Input the training and testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3794,
      "metadata": {
        "id": "v66HUClZcxaE"
      },
      "outputs": [],
      "source": [
        "training_dataroot = 'hw1_advanced_training.csv' # Training data file file named as 'hw1_basic_training.csv'\n",
        "testing_dataroot = 'hw1_advanced_testing.csv'   # Testing data file named as 'hw1_basic_training.csv'\n",
        "output_dataroot = 'hw1_advanced.csv' # Output file will be named as 'hw1_basic.csv'\n",
        "\n",
        "training_datalist =  [] # Training datalist, saved as numpy array\n",
        "testing_datalist =  [] # Testing datalist, saved as numpy array\n",
        "\n",
        "output_datalist =  [] # Your prediction, should be 220 * 1 matrix and saved as numpy array\n",
        "                      # The format of each row should be ['sbp']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1. read the training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3795,
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_data() -> (list, list, np.array):\n",
        "    train_id = []\n",
        "    train_time = []\n",
        "    train_data = []\n",
        "\n",
        "    training_data = []\n",
        "    with open(training_dataroot, newline='') as csvfile:\n",
        "        training_data = list(csv.reader(csvfile))[1 : ]\n",
        "\n",
        "    train_id = [int(data[0]) for data in training_data]\n",
        "\n",
        "    train_data = np.array([data[2 : ] for data in training_data])\n",
        "    train_data[train_data == ''] = np.nan\n",
        "    train_data = train_data.astype(float)\n",
        "\n",
        "    for data in training_data:\n",
        "        time_list = data[1].split(' ')\n",
        "        days_ago = int(time_list[0])\n",
        "\n",
        "        time = time_list[2].split(':')\n",
        "        hour, minute = int(time[0]), int(time[1])\n",
        "        train_time.append([days_ago, hour, minute])\n",
        "\n",
        "    return train_id, train_time, train_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2. preprocess the training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3796,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_incomplete_data(train_id: list, train_time: list, train_data: np.array) -> (list, list, np.array):\n",
        "    i = 0; train_nums = len(train_data)\n",
        "    while i < train_nums:\n",
        "        if np.sum(np.isnan(train_data[i])) >= 2:\n",
        "            train_data = np.delete(train_data, i, 0)\n",
        "            train_id.pop(i)\n",
        "            train_time.pop(i)\n",
        "            train_nums -= 1\n",
        "            i -= 1\n",
        "\n",
        "        if np.isnan(train_data[i][0]):\n",
        "            train_data[i][0] = train_data[i - 1][0]\n",
        "        elif np.isnan(train_data[i][1]):\n",
        "            train_data[i][1] = train_data[i - 1][1]\n",
        "        elif np.isnan(train_data[i][2]):\n",
        "            train_data[i][2] = train_data[i - 1][2]\n",
        "        elif np.isnan(train_data[i][3]):\n",
        "            train_data[i][3] = train_data[i - 1][3]\n",
        "\n",
        "        i += 1\n",
        "    return train_id, train_time, train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3797,
      "metadata": {},
      "outputs": [],
      "source": [
        "def divide_data(train_id: list, train_time: list, train_data: np.array) -> list:\n",
        "    ## We first divide the data into group by id\n",
        "    last_id = train_id[0]; group = []; tem_group = []\n",
        "    for i, data in enumerate(train_id):\n",
        "        tem_group.append(train_data[i])\n",
        "        if data != last_id:\n",
        "            group.append(tem_group)\n",
        "            tem_group = []\n",
        "            last_id = data\n",
        "    group.append(tem_group) # list-list-ndarray\n",
        "\n",
        "    ## Then we divide the data into group by time\n",
        "    new_group = []\n",
        "    for people in group:\n",
        "        morning, noon, afternoon, evening, night = [], [], [], [], []\n",
        "\n",
        "        for i in range(len(people)):\n",
        "            clock = train_time.pop(0)[1]\n",
        "            \n",
        "            if clock >= 6 and clock < 10:\n",
        "                morning.append([*train_data[i]])\n",
        "            elif clock >= 10 and clock < 14:\n",
        "                noon.append([*train_data[i]])\n",
        "            elif clock >= 14 and clock < 18:\n",
        "                afternoon.append([*train_data[i]])\n",
        "            elif clock >= 18 and clock < 22:\n",
        "                evening.append([*train_data[i]])\n",
        "            else:\n",
        "                night.append([*train_data[i]])\n",
        "        new_group.append([morning, noon, afternoon, evening, night])\n",
        "    return new_group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3798,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_outliers(group: list, width: float) -> list:\n",
        "    new_group = []\n",
        "\n",
        "    for people in group:\n",
        "        new_people = []\n",
        "\n",
        "        for time in people:\n",
        "            new_time = []\n",
        "\n",
        "            temperature = np.array([data[0] for data in time])\n",
        "            temperature_mean = np.mean(temperature); temperature_std = np.std(temperature)\n",
        "\n",
        "            heartrate = np.array([data[1] for data in time])\n",
        "            heartrate_mean = np.mean(heartrate); heartrate_std = np.std(heartrate)\n",
        "\n",
        "            resprate = np.array([data[2] for data in time])\n",
        "            resprate_mean = np.mean(resprate); resprate_std = np.std(resprate)\n",
        "\n",
        "            o2sat = np.array([data[3] for data in time])\n",
        "            o2sat_mean = np.mean(o2sat); o2sat_std = np.std(o2sat)\n",
        "\n",
        "            sbp = np.array([data[4] for data in time])\n",
        "            sbp_mean = np.mean(sbp); sbp_std = np.std(sbp)\n",
        "\n",
        "            temp_beyond_threshold = np.abs(temperature - temperature_mean) > width * temperature_std\n",
        "            heartrate_beyond_threshold = np.abs(heartrate - heartrate_mean) > width * heartrate_std\n",
        "            resprate_beyond_threshold = np.abs(resprate - resprate_mean) > width * resprate_std\n",
        "            o2sat_beyond_threshold = np.abs(o2sat - o2sat_mean) > width * o2sat_std\n",
        "            sbp_beyond_threshold = np.abs(sbp - sbp_mean) > width * sbp_std\n",
        "\n",
        "            for i in range(len(time)):\n",
        "                if temp_beyond_threshold[i] or heartrate_beyond_threshold[i] or resprate_beyond_threshold[i] or o2sat_beyond_threshold[i] or sbp_beyond_threshold[i]:\n",
        "                    continue\n",
        "                new_time.append(time[i])\n",
        "            new_people.append(time)\n",
        "        new_group.append(new_people)\n",
        "\n",
        "    return new_group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3799,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess(train_id: np.array, train_time: np.array, train_data: np.array, width: float) -> list:\n",
        "    '''\n",
        "    Assume the return value called list, then:\n",
        "        list: Whole data after preprocessing \\n\n",
        "        list[i]: Whole Data of the i-th person \\n\n",
        "        list[i][j]: Whole Data of the i-th person in the j-th time period \\n\n",
        "        list[i][j][k]: k-th Data of the i-th person in the j-th time period \\n\n",
        "        list[i][j][k][0]: Temperature of the k-th data of the i-th person in the j-th time period\n",
        "    '''\n",
        "    # remove the data with more than 2 elements missing\n",
        "    train_id, train_time, train_data = remove_incomplete_data(train_id, train_time, train_data)\n",
        "\n",
        "    # remove outliers\n",
        "    ## We first divide the data into group by id and time\n",
        "    group = divide_data(train_id, train_time, train_data)\n",
        "\n",
        "    ## Then we remove the data in each group once it has any outlier and return\n",
        "    return remove_outliers(group, width)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3. train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3800,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gradient_descent(y_ans: np.array, y_predict: np.array, x: np.array) -> np.array:\n",
        "    return (-2 * (y_ans - y_predict)).T.dot(x).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3801,
      "metadata": {},
      "outputs": [],
      "source": [
        "def Adam(gradient, coefficient, eta, m_t, v_t, n) -> np.array:\n",
        "    beta_1 = 0.9; beta_2 = 0.9; epsilon = 1e-7\n",
        "    m_t = beta_1 * m_t + (1 - beta_1) * gradient\n",
        "    v_t = beta_2 * v_t + (1 - beta_2) * (gradient ** 2)\n",
        "\n",
        "    m_hat = m_t / (1 - beta_1 ** n)\n",
        "    v_hat = v_t / (1 - beta_2 ** n)\n",
        "\n",
        "    return coefficient - eta * m_hat / (np.sqrt(v_hat) + epsilon)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3802,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(train_set: np.array, epoch: int, learning_rate: float, model: np.array) -> np.array:\n",
        "    '''\n",
        "    What I want to do: https://chat.openai.com/share/d4fa50cc-43d6-4651-93c7-9f42a8c49a3a\n",
        "    '''\n",
        "    eta = learning_rate\n",
        "    batch_nums = len(train_set)\n",
        "\n",
        "    plot_epoch = []; plot_train_MAPE = []; plot_validate_MAPE = []\n",
        "\n",
        "    MAPE_mean = 0\n",
        "    m_t = np.zeros((len(train_set[0][0]), 1)); v_t = np.zeros((len(train_set[0][0]), 1))\n",
        "    for e in range(epoch):\n",
        "        ith_validate = 0\n",
        "\n",
        "        validate_set = []; clean_train_set = []\n",
        "        for i ,batch in enumerate(train_set):\n",
        "            if i % batch_nums == ith_validate:\n",
        "                validate_set = batch\n",
        "                continue\n",
        "            \n",
        "            for datas in batch:\n",
        "                x = np.array([[1, *datas[ : -1]]]).astype(float)\n",
        "                y_ans = np.array([[datas[-1]]]).astype(float)\n",
        "                y_predict = x.dot(model).astype(int)\n",
        "\n",
        "                gradient = gradient_descent(y_ans, y_predict, x)\n",
        "                model = Adam(gradient, model, eta, m_t, v_t, i)\n",
        "\n",
        "            clean_train_set += batch\n",
        "            \n",
        "        validate_x = np.array([[1, *data[ : -1]] for data in validate_set]).astype(float)\n",
        "        validate_y = np.array([[data[-1]] for data in validate_set]).astype(float)\n",
        "        validate_y_prediction = validate_x.dot(model).astype(int)\n",
        "        MAPE_mean += MAPE(validate_y, validate_y_prediction)\n",
        "\n",
        "        clean_train_x = np.array([[1, *data[ : -1]] for data in clean_train_set]).astype(float)\n",
        "        clean_train_y = np.array([[data[-1]] for data in clean_train_set]).astype(float)\n",
        "        clean_train_y_prediction = clean_train_x.dot(model).astype(int)\n",
        "\n",
        "        plot_epoch.append(e + 1)\n",
        "        plot_validate_MAPE.append(MAPE(validate_y, validate_y_prediction))\n",
        "        plot_train_MAPE.append(MAPE(clean_train_y, clean_train_y_prediction))\n",
        "        \n",
        "    plt.plot(plot_epoch, plot_train_MAPE, 'blue')\n",
        "    plt.plot(plot_epoch, plot_validate_MAPE, 'red')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('MAPE')\n",
        "    plt.show()\n",
        "\n",
        "    print(f'MAPE = {MAPE_mean / epoch}')\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3803,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_2(datalist, epoch, learning_rate, model):\n",
        "    # random.shuffle(datalist)\n",
        "    nums = len(datalist)\n",
        "    train_set = datalist[ : int(nums * 0.8)]\n",
        "    validate_set = datalist[int(nums * 0.8) : ]\n",
        "\n",
        "    eta = learning_rate\n",
        "    plot_epoch = []; plot_train_MAPE = []; plot_validate_MAPE = []\n",
        "\n",
        "    m_t = np.zeros((len(train_set[0]), 1)); v_t = np.zeros((len(train_set[0]), 1))\n",
        "    for i, data in enumerate(train_set):\n",
        "        x = np.array([[1, *data[ : -1]]]).astype(float)\n",
        "        y_ans = np.array([[data[-1]]]).astype(float)\n",
        "        y_predict = x.dot(model).astype(int)\n",
        "\n",
        "        gradient = gradient_descent(y_ans, y_predict, x)\n",
        "        model = Adam(gradient, model, eta, m_t, v_t, i + 1)\n",
        "\n",
        "        plot_epoch.append(i + 1)\n",
        "        plot_train_MAPE.append(MAPE(y_ans, y_predict))\n",
        "\n",
        "    validate_x = np.array([[1, *data[ : -1]] for data in validate_set]).astype(float)\n",
        "    validate_y = np.array([[data[-1]] for data in validate_set]).astype(float)\n",
        "    validate_y_prediction = validate_x.dot(model).astype(int)\n",
        "    print(f'MAPE = {MAPE(validate_y, validate_y_prediction)}')\n",
        "\n",
        "    plt.plot(plot_epoch, plot_train_MAPE, 'blue')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('MAPE')\n",
        "    plt.show()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3804,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAPE = 16.594927120841316\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 4.87413366]\n",
            " [-0.32586635]\n",
            " [ 0.87413365]\n",
            " [ 0.67413365]\n",
            " [ 0.87413365]]\n"
          ]
        }
      ],
      "source": [
        "train_set = preprocess(*read_data(), 2)\n",
        "\n",
        "people_nums = len(train_set)\n",
        "morning_train_set = [train_set[i][0] for i in range(people_nums)]\n",
        "noon_train_set = [train_set[i][1] for i in range(people_nums)]\n",
        "afternoon_train_set = [train_set[i][2] for i in range(people_nums)]\n",
        "evening_train_set = [train_set[i][3] for i in range(people_nums)]\n",
        "night_train_set = [train_set[i][4] for i in range(people_nums)]\n",
        "\n",
        "a = []\n",
        "for time in train_set:\n",
        "    for people in time:\n",
        "        for data in people:\n",
        "            a.append(data)\n",
        "\n",
        "a_model = np.array([[5], [-0.2], [1], [0.8], [1]]).astype(float)\n",
        "a_model = train_2(a, 100, 0.001, a_model)\n",
        "print(a_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3805,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train_set = preprocess(*read_data(), 2.5)\n",
        "\n",
        "# people_nums = len(train_set)\n",
        "# morning_train_set = [train_set[i][0] for i in range(people_nums)]\n",
        "# noon_train_set = [train_set[i][1] for i in range(people_nums)]\n",
        "# afternoon_train_set = [train_set[i][2] for i in range(people_nums)]\n",
        "# evening_train_set = [train_set[i][3] for i in range(people_nums)]\n",
        "# night_train_set = [train_set[i][4] for i in range(people_nums)]\n",
        "\n",
        "# morning_model = np.array([[5], [-0.2], [1], [0.25], [1]]).astype(float) # const, temperature, heartrate, resprate, o2sat\n",
        "# morning_model = train(morning_train_set, len(morning_train_set) * 25, 0.00005, morning_model)\n",
        "# print(*morning_model)\n",
        "# print('-' * 80)\n",
        "\n",
        "# noon_model = np.array([[5], [-0.2], [1], [0.25], [1]]).astype(float)\n",
        "# noon_model = train(noon_train_set, len(noon_train_set) * 20, 0.001, noon_model)\n",
        "# print(*noon_model)\n",
        "# print('-' * 80)\n",
        "\n",
        "# afternoon_model = np.array([[5], [-0.2], [1], [0.25], [1]]).astype(float)\n",
        "# afternoon_model = train(afternoon_train_set, len(afternoon_train_set) * 20, 0.001, afternoon_model)\n",
        "# print(*afternoon_model)\n",
        "# print('-' * 80)\n",
        "\n",
        "# evening_model = np.array([[5], [-0.2], [1], [0.25], [1]]).astype(float)\n",
        "# evening_model = train(evening_train_set, len(evening_train_set) * 20, 0.001, evening_model)\n",
        "# print(*evening_model)\n",
        "# print('-' * 80)\n",
        "\n",
        "# night_model = np.array([[5], [-0.2], [1], [0.25], [1]]).astype(float)\n",
        "# night_model = train(night_train_set, len(night_train_set) * 20, 0.001, night_model)\n",
        "# print(*night_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Output your Prediction\n",
        "\n",
        "> your filename should be **hw1_advanced.csv**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3806,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(output_dataroot, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
        "  writer = csv.writer(csvfile)\n",
        "  for row in output_datalist:\n",
        "    writer.writerow(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtgCJU7FPeJL"
      },
      "source": [
        "# Report *(5%)*\n",
        "\n",
        "Report should be submitted as a pdf file **hw1_report.pdf**\n",
        "\n",
        "*   Briefly describe the difficulty you encountered\n",
        "*   Summarize your work and your reflections\n",
        "*   No more than one page\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlEE53_MPf4W"
      },
      "source": [
        "# Save the Code File\n",
        "Please save your code and submit it as an ipynb file! (**hw1.ipynb**)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
